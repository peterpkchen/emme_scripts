{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inro.modeller as m\n",
    "import os\n",
    "import glob\n",
    "mm = m.Modeller()\n",
    "eb = mm.emmebank\n",
    "import inro.emme.matrix as _matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "matrix_calculator = m.Modeller().tool(\"inro.emme.matrix_calculation.matrix_calculator\")\n",
    "create_matrix =  m.Modeller().tool(\"inro.emme.data.matrix.create_matrix\")\n",
    "change_matrix = m.Modeller().tool(\"inro.emme.data.matrix.change_matrix_properties\") \n",
    "import_matrices = mm.tool(\"tmg.input_output.import_binary_matrix\")  \n",
    "matrix_transaction = mm.tool('inro.emme.data.matrix.matrix_transaction')\n",
    "create_extra = m.Modeller().tool(\"inro.emme.data.extra_attribute.create_extra_attribute\")\n",
    "network_calc= m.Modeller().tool(\"inro.emme.network_calculation.network_calculator\")\n",
    "\n",
    "def import_matrices_from_directory(matrix_folder, matrix_list, extension, scenario):\n",
    "    import os\n",
    "    for root, dirs, files in os.walk(matrix_folder):\n",
    "        for matrix_file in files:\n",
    "            if matrix_file.endswith(extension):\n",
    "                name = os.path.splitext(matrix_file)[0]\n",
    "                if name in matrix_list:\n",
    "                    matrix_number = int(matrix_list[name][2:])\n",
    "                    import_matrices(4, matrix_number ,os.path.join(root, matrix_file),scenario, name.replace(\"skim.\",\"\").replace(\"transit.\",\"\").replace(\"peak\",\"pk\").replace(\" \",\"_\") )\n",
    "                    print \"Imported matrix \" + matrix_list[name]\n",
    "                    change_matrix(matrix = matrix_list[name],\n",
    "                        matrix_name = name.replace(\"skim.\",\"\").replace(\"transit.\",\"\").replace(\"peak\",\"pk\").replace(\" \",\"_\")[:40],\n",
    "                        matrix_description = name)\n",
    "    \n",
    "    #check\n",
    "    for name in matrix_list:\n",
    "        if eb.matrix(matrix_list[name]): \n",
    "            n_matrix = eb.matrix(matrix_list[name]).get_numpy_data(scenario)\n",
    "            if n_matrix.sum() == 0 :\n",
    "                print \"Matrix %s was not imported, or contains no values!\" % name\n",
    "        else:\n",
    "            print \"Matrix %s was not imported!\" % name\n",
    "    print \"Finished Importing Matrices\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "show_input": true
   },
   "outputs": [],
   "source": [
    "matrix_folder = r\"\\\\tore-infs01\\PWExternal\\451010\\281829_GGH\\GGHM Runs\\2051\\Preferred Network\\Preferred_Network_SList_APTG_2051_GGH_MTP_V106A3_CS222_20210305\\Daily Demand Matrices\"\n",
    "\n",
    "# peak period - 7 hrs\n",
    "sov_demand_pk = \"TRIPS SOV peak\"\n",
    "hov2_demand_pk = \"TRIPS HOV2 peak\"\n",
    "hov3_demand_pk = \"TRIPS HOV3 peak\"\n",
    "bike_demand_pk = \"TRIPS BIKE peak\"\n",
    "walk_demand_pk = \"TRIPS WALK peak\"\n",
    "transit_demand_pk = \"TRIPS TOTAL TRANSIT peak\"\n",
    "\n",
    "sov_demand_offpk = \"TRIPS SOV offpeak\"\n",
    "hov2_demand_offpk = \"TRIPS HOV2 offpeak\"\n",
    "hov3_demand_offpk = \"TRIPS HOV3 offpeak\"\n",
    "bike_demand_offpk = \"TRIPS BIKE offpeak\"\n",
    "walk_demand_offpk = \"TRIPS WALK offpeak\"\n",
    "transit_demand_offpk = \"TRIPS TOTAL TRANSIT offpeak\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIPS HOV3 offpeak\n",
      "TRIPS SOV peak\n",
      "TRIPS TOTAL TRANSIT offpeak\n",
      "TRIPS BIKE offpeak\n",
      "TRIPS HOV2 offpeak\n",
      "TRIPS HOV3 peak\n",
      "TRIPS SOV offpeak\n",
      "TRIPS BIKE peak\n",
      "TRIPS WALK offpeak\n",
      "TRIPS WALK peak\n",
      "TRIPS HOV2 peak\n",
      "TRIPS TOTAL TRANSIT peak\n",
      "Imported matrix mf107\n",
      "Imported matrix mf111\n",
      "Imported matrix mf108\n",
      "Imported matrix mf114\n",
      "Imported matrix mf104\n",
      "Imported matrix mf109\n",
      "Imported matrix mf110\n",
      "Imported matrix mf105\n",
      "Imported matrix mf106\n",
      "Imported matrix mf115\n",
      "Imported matrix mf112\n",
      "Imported matrix mf113\n",
      "Finished Importing Matrices\n"
     ]
    }
   ],
   "source": [
    "#matrices\n",
    "matrix_list = {\n",
    "    sov_demand_pk : \"\",\n",
    "    hov2_demand_pk : \"\",\n",
    "    hov3_demand_pk : \"\",\n",
    "    bike_demand_pk : \"\",\n",
    "    walk_demand_pk : \"\",\n",
    "    transit_demand_pk : \"\",\n",
    "    sov_demand_offpk : \"\",\n",
    "    hov2_demand_offpk : \"\",\n",
    "    hov3_demand_offpk : \"\",\n",
    "    bike_demand_offpk:\"\",\n",
    "    walk_demand_offpk:\"\",\n",
    "    transit_demand_offpk:\"\"}\n",
    "\n",
    "#Import matrices\n",
    "for matrix_name in matrix_list.keys():\n",
    "    matrix_list[matrix_name] = eb.available_matrix_identifier('FULL')\n",
    "    print matrix_name\n",
    "    create_matrix(matrix_id = matrix_list[matrix_name],\n",
    "                  matrix_name= matrix_name.replace(\"skim.\",\"\").replace(\"transit.\",\"\").replace(\"peak\",\"pk\").replace(\" \",\"_\").strip()[:40],\n",
    "                  matrix_description = matrix_name)\n",
    "\n",
    "import_matrices_from_directory(matrix_folder, matrix_list, \".mdf\",701) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_to_pddf(id, scen):\n",
    "    mat = eb.matrix(id).get_data(scen)\n",
    "    zones_tupl = mat.indices\n",
    "    indices = pd.Index(zones_tupl[0])\n",
    "    indices.name = 'p'\n",
    "    cols = pd.Index(zones_tupl[1])\n",
    "    cols.name = 'q'\n",
    "    matrix = mat.to_numpy()\n",
    "    return pd.DataFrame(matrix, index=indices, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf107 = mat_to_pddf(\"mf107\", 701)\n",
    "mf111 = mat_to_pddf(\"mf111\", 701)\n",
    "mf108 = mat_to_pddf(\"mf108\", 701)\n",
    "mf114 = mat_to_pddf(\"mf114\", 701)\n",
    "mf104 = mat_to_pddf(\"mf104\", 701)\n",
    "mf109 = mat_to_pddf(\"mf109\", 701)\n",
    "mf110 = mat_to_pddf(\"mf110\", 701)\n",
    "mf105 = mat_to_pddf(\"mf105\", 701)\n",
    "mf106 = mat_to_pddf(\"mf106\", 701)\n",
    "mf115 = mat_to_pddf(\"mf115\", 701)\n",
    "mf112 = mat_to_pddf(\"mf112\", 701)\n",
    "mf113 = mat_to_pddf(\"mf113\", 701)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_pass_peak = (mf114 + mf109) - (mf114 / 2.2 + mf109 / 3.3)\n",
    "auto_pass_offpk = (mf104 + mf108) - (mf108 / 2.2 + mf104 / 3.3)\n",
    "auto_drive_peak = mf105 + (mf114 / 2.2 + mf109 / 3.3)\n",
    "auto_drive_offpk = mf110 + (mf108 / 2.2 + mf104 / 3.3)\n",
    "active_peak = mf111 + mf113\n",
    "active_offpk = mf107 + mf112\n",
    "transit_peak = mf115\n",
    "transit_offpk = mf106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = {'auto_drive': [auto_drive_peak.sum().sum(), auto_drive_offpk.sum().sum()],\n",
    "      'auto_pass':[auto_pass_peak.sum().sum(), auto_pass_offpk.sum().sum()],\n",
    "      'active':[active_peak.sum().sum(), active_offpk.sum().sum()], \n",
    "      'transit':[transit_peak.sum().sum(), transit_offpk.sum().sum()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_df = pd.DataFrame.from_dict(totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>active</th>\n",
       "      <th>auto_drive</th>\n",
       "      <th>auto_pass</th>\n",
       "      <th>transit</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>peak</th>\n",
       "      <td>1.287652e+06</td>\n",
       "      <td>12224599.0</td>\n",
       "      <td>4837897.0</td>\n",
       "      <td>2629334.25</td>\n",
       "      <td>2.097948e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offpk</th>\n",
       "      <td>4.339759e+05</td>\n",
       "      <td>9395972.0</td>\n",
       "      <td>3791637.5</td>\n",
       "      <td>1396536.25</td>\n",
       "      <td>1.501812e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily</th>\n",
       "      <td>1.721628e+06</td>\n",
       "      <td>21620571.0</td>\n",
       "      <td>8629534.5</td>\n",
       "      <td>4025870.50</td>\n",
       "      <td>3.599760e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             active  auto_drive  auto_pass     transit         total\n",
       "peak   1.287652e+06  12224599.0  4837897.0  2629334.25  2.097948e+07\n",
       "offpk  4.339759e+05   9395972.0  3791637.5  1396536.25  1.501812e+07\n",
       "daily  1.721628e+06  21620571.0  8629534.5  4025870.50  3.599760e+07"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals_fin = totals_df.rename(index = {0 : 'peak', 1 : 'offpk'})\n",
    "totals_fin.loc['daily',:] = totals_fin.sum(axis=0)\n",
    "totals_fin.loc[:,'total'] = totals_fin.sum(axis=1)\n",
    "totals_fin.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_fin.to_csv('C:\\Users\\pechen\\Desktop\\GGH\\prefnet_trips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "modeller": {
   "desktop_app_port": "60346"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
